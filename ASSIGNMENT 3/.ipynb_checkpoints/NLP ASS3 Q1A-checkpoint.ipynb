{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8124238,"sourceType":"datasetVersion","datasetId":4800974},{"sourceType":"datasetVersion","sourceId":8139795,"datasetId":4812394}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\n\ndef generate_random_numbers(min_value, max_value, num_numbers):\n \n  return random.sample(range(min_value, max_value + 1), num_numbers)\n\n# Generate 1000 random numbers between 1 and 2390\nmin_value = 1\nmax_value = 2390\nnum_numbers = 1000\n\nrandom_numbers = generate_random_numbers(min_value, max_value, num_numbers)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\ndef extract_lines(filepath, random_numbers):\n  \"\"\"\n  This function extracts lines from a file based on a list of random numbers.\n\n  Args:\n      filepath: The path to the file.\n      random_numbers: A list of random numbers representing line indices to extract.\n\n  Returns:\n      A list of extracted lines from the file.\n  \"\"\"\n  with open(filepath, 'r') as file:\n    lines = file.readlines()\n  extracted_lines = [lines[i-1] for i in random_numbers]  # Adjust for 0-based indexing\n  return extracted_lines\n\ndef create_new_files(file_paths, random_numbers, output_filenames):\n  \"\"\"\n  This function creates three new files and writes lines extracted based on random numbers.\n\n  Args:\n      file_paths: A list containing the paths to the three original files.\n      random_numbers: A list containing 1000 random numbers (assumed to be the same for all files).\n      output_filenames: A list containing the names of the three output text files.\n  \"\"\"\n  if len(file_paths) != len(output_filenames):\n    raise ValueError(\"Number of file paths and output filenames must match.\")\n\n  for i in range(len(file_paths)):\n    extracted_lines = extract_lines(file_paths[i], random_numbers)\n    with open(output_filenames[i], 'w') as output_file:\n      output_file.writelines(extracted_lines)\n\n# Example usage\nfile_paths = [\"/kaggle/input/test-txt/test.en\", \"/kaggle/input/test-txt/test.gu\", \"/kaggle/input/test-txt/test.hi\"]\n# Assuming you already have the 1000 random numbers in a list named `random_numbers`\noutput_filenames = [\"extracted_eng.txt\", \"extracted_guj2.txt\", \"extracted_hi.txt\"]\n\ncreate_new_files(file_paths, random_numbers, output_filenames)\n\nprint(f\"New files created with extracted lines: {', '.join(output_filenames)}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ndef translate_sentences(model, tokenizer, input_file, output_file):\n    # Read English sentences from the input file\n    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n        english_sentences = f.readlines()\n\n    # Translate each English sentence to Hindi\n    hindi_translations = []\n    for sentence in english_sentences:\n        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n        translated_tokens = model.generate(\n            **inputs,\n            forced_bos_token_id=tokenizer.lang_code_to_id[\"hin_Deva\"],\n            max_length=100\n        )\n        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n        hindi_translations.append(translated_sentence)\n\n    # Write the Hindi translations to the output file\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        for translation in hindi_translations:\n            f.write(translation + \"\\n\")\n\n# Load the model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"eng_Latn\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n\n# Path to the input file containing English sentences\ninput_file_path = \"/kaggle/input/extracted3/extracted_eng.txt\"\n\n# Path to the output file where Hindi translations will be stored\noutput_file_path = \"english_to_hindi_translations_1A.txt\"\n\n# Translate sentences and store the translations in the output file\ntranslate_sentences(model, tokenizer, input_file_path, output_file_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ndef translate_sentences(model, tokenizer, input_file, output_file):\n    # Read English sentences from the input file\n    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n        english_sentences = f.readlines()\n\n    # Translate each English sentence to Hindi\n    hindi_translations = []\n    for sentence in english_sentences:\n        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n        translated_tokens = model.generate(\n            **inputs,\n            forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"],\n            max_length=100\n        )\n        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n        hindi_translations.append(translated_sentence)\n\n    # Write the Hindi translations to the output file\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        for translation in hindi_translations:\n            f.write(translation + \"\\n\")\n\n# Load the model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"hin_Deva\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n\n# Path to the input file containing English sentences\ninput_file_path = \"/kaggle/input/extracted3/extracted_hi.txt\"\n\n# Path to the output file where Hindi translations will be stored\noutput_file_path = \"hindi_to_english_translations_1A.txt\"\n\n# Translate sentences and store the translations in the output file\ntranslate_sentences(model, tokenizer, input_file_path, output_file_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ndef translate_sentences(model, tokenizer, input_file, output_file):\n    # Read English sentences from the input file\n    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n        english_sentences = f.readlines()\n\n    # Translate each English sentence to Hindi\n    hindi_translations = []\n    for sentence in english_sentences:\n        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n        translated_tokens = model.generate(\n            **inputs,\n            forced_bos_token_id=tokenizer.lang_code_to_id[\"guj_Gujr\"],\n            max_length=100\n        )\n        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n        hindi_translations.append(translated_sentence)\n\n    # Write the Hindi translations to the output file\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        for translation in hindi_translations:\n            f.write(translation + \"\\n\")\n\n# Load the model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"hin_Deva\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n\n# Path to the input file containing English sentences\ninput_file_path = \"/kaggle/input/extracted3/extracted_hi.txt\"\n\n# Path to the output file where Hindi translations will be stored\noutput_file_path = \"hindi_to_gujrati_translations_1A.txt\"\n\n# Translate sentences and store the translations in the output file\ntranslate_sentences(model, tokenizer, input_file_path, output_file_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ndef translate_sentences(model, tokenizer, input_file, output_file):\n    # Read English sentences from the input file\n    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n        english_sentences = f.readlines()\n\n    # Translate each English sentence to Hindi\n    hindi_translations = []\n    for sentence in english_sentences:\n        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n        translated_tokens = model.generate(\n            **inputs,\n            forced_bos_token_id=tokenizer.lang_code_to_id[\"hin_Deva\"],\n            max_length=100\n        )\n        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n        hindi_translations.append(translated_sentence)\n\n    # Write the Hindi translations to the output file\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        for translation in hindi_translations:\n            f.write(translation + \"\\n\")\n\n# Load the model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"guj_Gujr\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n\n# Path to the input file containing English sentences\ninput_file_path = \"/kaggle/input/extracted3/extracted_guj2.txt\"\n\n# Path to the output file where Hindi translations will be stored\noutput_file_path = \"gujrati_to_hindi_translations_1A.txt\"\n\n# Translate sentences and store the translations in the output file\ntranslate_sentences(model, tokenizer, input_file_path, output_file_path)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}