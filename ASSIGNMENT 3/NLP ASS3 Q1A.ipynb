{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_numbers(min_value, max_value, num_numbers):\n",
    " \n",
    "  return random.sample(range(min_value, max_value + 1), num_numbers)\n",
    "\n",
    "# Generate 1000 random numbers between 1 and 2390\n",
    "min_value = 1\n",
    "max_value = 2390\n",
    "num_numbers = 1000\n",
    "\n",
    "random_numbers = generate_random_numbers(min_value, max_value, num_numbers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def extract_lines(filepath, random_numbers):\n",
    "  \"\"\"\n",
    "  This function extracts lines from a file based on a list of random numbers.\n",
    "\n",
    "  Args:\n",
    "      filepath: The path to the file.\n",
    "      random_numbers: A list of random numbers representing line indices to extract.\n",
    "\n",
    "  Returns:\n",
    "      A list of extracted lines from the file.\n",
    "  \"\"\"\n",
    "  with open(filepath, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "  extracted_lines = [lines[i-1] for i in random_numbers]  # Adjust for 0-based indexing\n",
    "  return extracted_lines\n",
    "\n",
    "def create_new_files(file_paths, random_numbers, output_filenames):\n",
    "  \"\"\"\n",
    "  This function creates three new files and writes lines extracted based on random numbers.\n",
    "\n",
    "  Args:\n",
    "      file_paths: A list containing the paths to the three original files.\n",
    "      random_numbers: A list containing 1000 random numbers (assumed to be the same for all files).\n",
    "      output_filenames: A list containing the names of the three output text files.\n",
    "  \"\"\"\n",
    "  if len(file_paths) != len(output_filenames):\n",
    "    raise ValueError(\"Number of file paths and output filenames must match.\")\n",
    "\n",
    "  for i in range(len(file_paths)):\n",
    "    extracted_lines = extract_lines(file_paths[i], random_numbers)\n",
    "    with open(output_filenames[i], 'w') as output_file:\n",
    "      output_file.writelines(extracted_lines)\n",
    "\n",
    "# Example usage\n",
    "file_paths = [\"/kaggle/input/test-txt/test.en\", \"/kaggle/input/test-txt/test.gu\", \"/kaggle/input/test-txt/test.hi\"]\n",
    "# Assuming you already have the 1000 random numbers in a list named `random_numbers`\n",
    "output_filenames = [\"extracted_eng.txt\", \"extracted_guj2.txt\", \"extracted_hi.txt\"]\n",
    "\n",
    "create_new_files(file_paths, random_numbers, output_filenames)\n",
    "\n",
    "print(f\"New files created with extracted lines: {', '.join(output_filenames)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def translate_sentences(model, tokenizer, input_file, output_file):\n",
    "    # Read English sentences from the input file\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        english_sentences = f.readlines()\n",
    "\n",
    "    # Translate each English sentence to Hindi\n",
    "    hindi_translations = []\n",
    "    for sentence in english_sentences:\n",
    "        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n",
    "        translated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"hin_Deva\"],\n",
    "            max_length=100\n",
    "        )\n",
    "        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "        hindi_translations.append(translated_sentence)\n",
    "\n",
    "    # Write the Hindi translations to the output file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for translation in hindi_translations:\n",
    "            f.write(translation + \"\\n\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"eng_Latn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "# Path to the input file containing English sentences\n",
    "input_file_path = \"/kaggle/input/extracted3/extracted_eng.txt\"\n",
    "\n",
    "# Path to the output file where Hindi translations will be stored\n",
    "output_file_path = \"english_to_hindi_translations_1A.txt\"\n",
    "\n",
    "# Translate sentences and store the translations in the output file\n",
    "translate_sentences(model, tokenizer, input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def translate_sentences(model, tokenizer, input_file, output_file):\n",
    "    # Read English sentences from the input file\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        english_sentences = f.readlines()\n",
    "\n",
    "    # Translate each English sentence to Hindi\n",
    "    hindi_translations = []\n",
    "    for sentence in english_sentences:\n",
    "        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n",
    "        translated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"],\n",
    "            max_length=100\n",
    "        )\n",
    "        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "        hindi_translations.append(translated_sentence)\n",
    "\n",
    "    # Write the Hindi translations to the output file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for translation in hindi_translations:\n",
    "            f.write(translation + \"\\n\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"hin_Deva\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "# Path to the input file containing English sentences\n",
    "input_file_path = \"/kaggle/input/extracted3/extracted_hi.txt\"\n",
    "\n",
    "# Path to the output file where Hindi translations will be stored\n",
    "output_file_path = \"hindi_to_english_translations_1A.txt\"\n",
    "\n",
    "# Translate sentences and store the translations in the output file\n",
    "translate_sentences(model, tokenizer, input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def translate_sentences(model, tokenizer, input_file, output_file):\n",
    "    # Read English sentences from the input file\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        english_sentences = f.readlines()\n",
    "\n",
    "    # Translate each English sentence to Hindi\n",
    "    hindi_translations = []\n",
    "    for sentence in english_sentences:\n",
    "        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n",
    "        translated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"guj_Gujr\"],\n",
    "            max_length=100\n",
    "        )\n",
    "        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "        hindi_translations.append(translated_sentence)\n",
    "\n",
    "    # Write the Hindi translations to the output file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for translation in hindi_translations:\n",
    "            f.write(translation + \"\\n\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"hin_Deva\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "# Path to the input file containing English sentences\n",
    "input_file_path = \"/kaggle/input/extracted3/extracted_hi.txt\"\n",
    "\n",
    "# Path to the output file where Hindi translations will be stored\n",
    "output_file_path = \"hindi_to_gujrati_translations_1A.txt\"\n",
    "\n",
    "# Translate sentences and store the translations in the output file\n",
    "translate_sentences(model, tokenizer, input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def translate_sentences(model, tokenizer, input_file, output_file):\n",
    "    # Read English sentences from the input file\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        english_sentences = f.readlines()\n",
    "\n",
    "    # Translate each English sentence to Hindi\n",
    "    hindi_translations = []\n",
    "    for sentence in english_sentences:\n",
    "        inputs = tokenizer(sentence.strip(), return_tensors=\"pt\")\n",
    "        translated_tokens = model.generate(\n",
    "            **inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"hin_Deva\"],\n",
    "            max_length=100\n",
    "        )\n",
    "        translated_sentence = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "        hindi_translations.append(translated_sentence)\n",
    "\n",
    "    # Write the Hindi translations to the output file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for translation in hindi_translations:\n",
    "            f.write(translation + \"\\n\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\", src_lang=\"guj_Gujr\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "# Path to the input file containing English sentences\n",
    "input_file_path = \"/kaggle/input/extracted3/extracted_guj2.txt\"\n",
    "\n",
    "# Path to the output file where Hindi translations will be stored\n",
    "output_file_path = \"gujrati_to_hindi_translations_1A.txt\"\n",
    "\n",
    "# Translate sentences and store the translations in the output file\n",
    "translate_sentences(model, tokenizer, input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4800974,
     "sourceId": 8124238,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4812394,
     "sourceId": 8139795,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
